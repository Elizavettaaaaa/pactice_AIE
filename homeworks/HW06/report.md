# HW06 – Report

## 1. Dataset

- **Датасет:** `S06-hw-dataset-02.csv`
- **Размер:** 18 000 строк, 38 столбцов (после удаления ID — 37 признаков).
- **Целевая переменная:** `target`. Наблюдается дисбаланс классов:
  - Класс 0: **73.7%**
  - Класс 1: **26.3%**
- **Признаки:** Все признаки числовые (вещественные `float64`).

## 2. Protocol

- **Разбиение:** Train/Test в пропорции **75% / 25%** (13500 строк в обучении, 4500 в тесте).
- **Параметры:** Использовался фиксированный `random_state=42` и стратификация (`stratify=y`) для сохранения баланса классов.
- **Подбор:** GridSearchCV на 5 фолдов (StratifiedKFold) на обучающей выборке. Оптимизируемая метрика — `ROC-AUC`.
- **Метрики:**
  - `ROC-AUC` — основная метрика для оценки качества ранжирования (особенно важна при дисбалансе).
  - `F1-score` — для оценки точности и полноты.
  - `Accuracy` — справочно (но менее показательна из-за дисбаланса).

## 3. Models

Сравнивались следующие модели:

1.  **DummyClassifier:** Бейзлайн (стратегия `most_frequent`). Всегда предсказывает класс 0.
2.  **LogisticRegression:** Линейный бейзлайн (с предварительной стандартизацией `StandardScaler`).
3.  **DecisionTreeClassifier:** Одиночное дерево решений. Подбирались `max_depth` и `min_samples_leaf`.
4.  **RandomForestClassifier:** Бэггинг (ансамбль деревьев). Использована облегченная сетка параметров для ускорения (`n_jobs=1`).
5.  **GradientBoostingClassifier:** Бустинг. Последовательное построение деревьев.
6.  **StackingClassifier:** Мета-ансамбль, объединяющий предсказания Дерева, Леса и Бустинга. Мета-модель — Логистическая регрессия.

## 4. Results

Результаты на отложенной тестовой выборке (сортировка по ROC-AUC):

| Model | ROC-AUC | Accuracy | F1 Score |
|-------|---------|----------|----------|
| **Stacking** | **0.9318** | **0.9147** | **0.8269** |
| RandomForest | 0.9291 | 0.8924 | 0.7597 |
| GradientBoosting | 0.8800 | 0.8447 | 0.6224 |
| DecisionTree | 0.8397 | 0.8322 | 0.6535 |
| LogisticRegression | 0.8009 | 0.8162 | 0.5717 |
| Dummy | 0.5000 | 0.7373 | 0.0000 |

**Победитель:** `StackingClassifier`.
Он показал наивысший ROC-AUC (0.932) и лучший F1-score (0.827), что говорит о том, что композиция моделей лучше справляется с поиском сложных зависимостей, чем каждая модель по отдельности.

## 5. Analysis

- **Линейность vs Нелинейность:** Логистическая регрессия (0.80 ROC-AUC) значительно уступила даже одиночному дереву (0.84), а тем более ансамблям. Это подтверждает, что в данных присутствуют сложные нелинейные зависимости.
- **Ансамбли:** RandomForest и Stacking показали лучшие результаты. Random Forest оказался очень сильным алгоритмом "из коробки". Бустинг в данном эксперименте немного отстал (возможно, из-за ограничения параметров для скорости), но Стекинг смог "вытянуть" пользу из всех моделей.
- **Интерпретация:** Анализ `permutation_importance` (для GradientBoosting) выделил топ самых важных признаков:
  1. `f16` (наибольшее влияние)
  2. `f01`
  3. `f19`
  Эти признаки вносят основной вклад в разделение классов.

## 6. Conclusion

1.  Данные имеют выраженную нелинейную структуру, простые линейные модели здесь работают плохо.
2.  Ансамблирование (особенно Стекинг и Случайный лес) дает существенный прирост качества (+13% ROC-AUC относительно линейной модели).
3.  Стекинг позволяет объединить предсказания разных алгоритмов и получить метрику выше, чем у любого из них по отдельности.
4.  Соблюдение протокола (GridSearch только на train, фиксированный seed) гарантирует, что полученные оценки качества честные и воспроизводимые.