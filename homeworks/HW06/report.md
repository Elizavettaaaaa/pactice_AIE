# HW06 – Report

## 1. Dataset

- **Какой датасет выбран:** `S06-hw-dataset-04.csv`
- **Размер:** 25 000 строк, 61 признак (после удаления ID).
- **Целевая переменная:** `target`.
  - Класс 0: ~95%
  - Класс 1: ~5% (Сильный дисбаланс классов).
- **Признаки:** Все признаки числовые (`float64`), категориальных нет.

## 2. Protocol

- **Разбиение:** Train/Test в пропорции 80% / 20%, `random_state=42`, с обязательной стратификацией (`stratify=y`) из-за дисбаланса.
- **Подбор:** Использовался `GridSearchCV` на train-выборке (Cross-Validation 3-5 фолдов). Оптимизировали метрику `ROC-AUC`.
- **Метрики:**
  - `ROC-AUC`: Основная метрика для оценки качества ранжирования (не зависит от порога).
  - `F1`: Важна для оценки баланса точности и полноты на дисбалансе.
  - `accuracy`: Справочно (на дисбалансе может быть обманчиво высокой).

## 3. Models

Сравнивались следующие модели:

- **DummyClassifier** (baseline): Стратегия `most_frequent` (всегда предсказывает класс 0).
- **LogisticRegression** (baseline из S05): Использовалась в Pipeline с `StandardScaler`.
- **DecisionTreeClassifier**: Контроль сложности осуществлялся через параметр `ccp_alpha` (Cost-Complexity Pruning) для обрезки дерева.
- **RandomForestClassifier**: Ансамбль (бэггинг). Подбирались параметры `max_depth` (ограничение глубины), `min_samples_leaf` (ограничение переобучения в листьях) и `max_features`.
- **GradientBoosting (HistGradientBoosting)**: Градиентный бустинг. Подбирались `learning_rate` (скорость обучения), `max_depth` и количество итераций.

## 4. Results

Таблица финальных метрик на test:

| Model | ROC-AUC | Accuracy | F1 |
|-------|---------|----------|----|
| **GradientBoosting** | **0.8960** | **0.9762** | **0.6925** |
| RandomForest | 0.8922 | 0.9674 | 0.5076 |
| LogisticRegression | 0.8340 | 0.9632 | 0.4286 |
| DecisionTree | 0.7457 | 0.9452 | 0.4850 |
| Dummy | 0.5000 | 0.9508 | 0.0000 |

**Победитель:** `GradientBoostingClassifier` (HistGradientBoosting).
Модель показала наивысший ROC-AUC и, что важнее, значительно превзошла остальные по F1-мере (0.69 против 0.50 у леса), что критично для задачи с сильным дисбалансом.

## 5. Analysis

- **Устойчивость:** Ансамбли (Random Forest и Boosting) показали более стабильные результаты по сравнению с одиночным деревом, которое склонно к переобучению и высокой дисперсии. Фиксация `random_state=42` обеспечила воспроизводимость.
- **Ошибки:** Confusion Matrix для лучшей модели (GradientBoosting) показывает, что модель успешно находит значительную часть объектов минорного класса (True Positives), сохраняя низкий уровень ложных срабатываний (False Positives), в отличие от Dummy, которая просто игнорирует минорный класс.
- **Интерпретация:** Анализ `permutation_importance` выделил ключевые признаки. Топ-3 важных признака: **f25**, **f58**, **f54**. Остальные признаки вносят значительно меньший вклад.

## 6. Conclusion

1. На данных с сильным дисбалансом метрика Accuracy бесполезна (Dummy дает 95%), необходимо ориентироваться на ROC-AUC и F1.
2. Линейная модель (LogisticRegression) работает хуже ансамблей, что указывает на наличие нелинейных зависимостей в данных.
3. Градиентный бустинг лучше всего справился с задачей выделения редкого класса, показав лучший баланс точности и полноты.
4. Контроль сложности (прунинг деревьев, глубина леса/бустинга) обязателен для получения адекватных результатов на тесте.